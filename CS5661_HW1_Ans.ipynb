{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS 5661 Homework 1\n",
    "### Jagannathan Chengavalli Lakshminarayanan - 305834859"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Importing necessary sklearn packages\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Importing the required packages and libraries\n",
    "# we will need numpy and pandas later\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# reading a CSV file directly from Web, and store it in a pandas DataFrame:\n",
    "# \"read_csv\" is a pandas function to read csv files from web or local device:\n",
    "df = pd.read_csv('C:/Users/harish/Desktop/Spring18/CS5661/HW/HW1/Cancer_small.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b), c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 9)\n"
     ]
    }
   ],
   "source": [
    "# Creating the Feature Matrix for given dataset:\n",
    "\n",
    "# create a python list of feature names that would like to pick from the dataset:\n",
    "feature_cols = ['Clump_Thickness','Uniformity_of_Cell_Size','Uniformity_of_Cell_Shape','Marginal_Adhesion',\n",
    "                'Single_Epithelial_Cell_Size','Bare_Nuclei','Bland_Chromatin','Normal_Nucleoli','Mitoses']\n",
    "\n",
    "# use the above list to select the features from the original DataFrame\n",
    "X = df[feature_cols]  \n",
    "\n",
    "# select a Series of labels (the last column) from the DataFrame\n",
    "y = df['Malignant_Cancer']\n",
    "\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Randomly splitting the original dataset into training set and testing set\n",
    "# The function\"train_test_split\" from \"sklearn.cross_validation\" library performs random splitting.\n",
    "# \"test_size=0.3\" means that pick 30% of data samples for testing set, and the rest (70%) for training set.\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=2)\n",
    "\n",
    "#print(len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Performing bagging \n",
    "new_predictions = []\n",
    "\n",
    "# 'For' loop for bootstrapping by creating new training sets and base decision tree\n",
    "for i in range(19):\n",
    "    bootstarp_size = 0.8*len(df)\n",
    "    #print(bootstarp_size)\n",
    "    X_new_train, y_new_train= resample(X_train,y_train, n_samples = 160 , random_state=i , replace = True) \n",
    "    Base_DecisionTree = DecisionTreeClassifier(random_state=2)\n",
    "    Base_DecisionTree.fit(X_new_train, y_new_train)\n",
    "    y_new_predict = Base_DecisionTree.predict(X_test)\n",
    "    new_predictions.append(y_new_predict)\n",
    "\n",
    "\n",
    "# Transposing rows and columns\n",
    "sample_ar = [list(i) for i in zip(*new_predictions)]\n",
    "\n",
    "# Defining the Voting logic    \n",
    "new_voting_list = []\n",
    "count_zeroes = 0\n",
    "count_ones = 0\n",
    "\n",
    "for i in range(len(sample_ar)):\n",
    "    for j in range(len(sample_ar[i])):\n",
    "        if(sample_ar[i][j] == 0):\n",
    "            count_zeroes = count_zeroes + 1\n",
    "        elif(sample_ar[i][j] == 1):\n",
    "            count_ones = count_ones + 1\n",
    "    if(count_zeroes > count_ones):\n",
    "        new_voting_list.append(0)\n",
    "        count_zeroes = 0\n",
    "        count_ones = 0\n",
    "    else:\n",
    "        new_voting_list.append(1)\n",
    "        count_ones = 0\n",
    "        count_zeroes = 0\n",
    "\n",
    "\n",
    "#for j,pred in enumerate(sample_ar):\n",
    "#    print(\"{} {}\".format(j,pred))\n",
    "\n",
    "#for j,pred in enumerate(new_predictions):\n",
    "#    print(\"\\n {} \\n \\n {}\".format(j,pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## e), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_decisiontree = DecisionTreeClassifier(random_state=2)\n",
    "\n",
    "my_decisiontree.fit(X_train, y_train)\n",
    "\n",
    "y_predict_dt = my_decisiontree.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_AdaBoost = AdaBoostClassifier(n_estimators = 19,random_state=2)\n",
    "\n",
    "my_AdaBoost.fit(X_train, y_train)\n",
    "\n",
    "y_predict_AdaB = my_AdaBoost.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_RandomForest =  RandomForestClassifier(n_estimators = 19, bootstrap = True, random_state=2)\n",
    "\n",
    "my_RandomForest.fit(X_train, y_train)\n",
    "\n",
    "y_predict_RF = my_RandomForest.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DECISION TREE ACCURACY: 0.866666666667\n",
      "AdaBoost ACCURACY: 0.933333333333\n",
      "RANDOM FOREST ACCURACY: 0.955555555556\n",
      "BAGGING ACCURACY:  0.888888888889\n"
     ]
    }
   ],
   "source": [
    "# We can now compare the \"predicted labels\" for the Testing Set with its \"actual labels\" to evaluate the accuracy \n",
    "# Function \"accuracy_score\" from \"sklearn.metrics\" will perform the element-to-element comparision and returns the \n",
    "# portion of correct predictions:\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "score_dt = accuracy_score(y_test, y_predict_dt)\n",
    "score_ada = accuracy_score(y_test, y_predict_AdaB)\n",
    "score_rf = accuracy_score(y_test, y_predict_RF)\n",
    "score_boots = accuracy_score(y_test, new_voting_list)\n",
    "\n",
    "print('DECISION TREE ACCURACY:',score_dt)\n",
    "print('AdaBoost ACCURACY:', score_ada)\n",
    "print('RANDOM FOREST ACCURACY:', score_rf)\n",
    "print('BAGGING ACCURACY: ', score_boots)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
